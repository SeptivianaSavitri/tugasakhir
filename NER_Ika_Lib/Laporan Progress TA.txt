1. install nltk dari python
2. language detection tool dalam java
3. target sampai step 7

studi literatur : SIM, SIL, ELSEFIER, IEEE


1. Get the wikipedia dump
Source : https://dumps.wikimedia.org/idwiki/latest/
Data yang dipilih : idwiki-20170120-pages-articles-multistream.xml

2. Use WikiExtractor.py to get content of Wikipedia dump
Source code : https://github.com/attardi/wikiextractor
Syntax : python WikiExtractor.py idwiki-20170120-pages-articles-multistream.xml -b 500K -o extracted
Input : idwiki-20170120-pages-articles-multistream.xml
Output : Folder extracted yang berisi folder AA....ZZ dengan setiap folder berisi maksimal 100 data.

3. Use Data1_ArticleAndParagraphSelector.py to get list of paragraphs that certain criterias for each folder from step 2
Fungsi : menghitung paragraf yang bakal diambil dan juga ngebersihin tag dari wiki. 
input : wikitext/AA/ ->isi nya ada wiki_00 sampai wiki_99 () data yang jumlahnya 100 (or less) yang uda diproses WikiExtractor). 
output: data/training/prep/paragraphs_test.txt  ->  list of paragraf yang sudah bersih dari tag html

4. Use Data2_FileCombiner.py to combine all files resulted from step 3
Fungsi : menggabungkan file file output langkah 3 (kan bisa AA ... ZZ) untuk dijadikan satu file
Input  : output langkah 3 untuk file-file berbeda (jumlah file bebas).
output : data/training/prep/allParagraphs.txt  ->  satu file hasil penggabungan biar lebih ringkas.


5. Use Data3_SentencerNltk/py to extract sentences from step 4
Requirement : Python 3.5, NLTK , NLTK Data
Fungsi		: Dari list of paragraph diubah menjadi list of sentences (memotong paragraf menjadi kalimat dengan bantuan NLTK).
input       : data/training/prep/allParagraphs.txt -? list of paragraphs
output      : data/training/prep/allSentences.txt -> list of sentences hasil pecahan paragraf file input.


6. Use Data4_SentencesFilter.py to filter sentences that meet certain criterias
Fungsi 	 : Memilih kalimat yang sesuai dengan kriteria.
Kriteria : Suatu kalimat dipilih jika memenuhi -> Terdiri dari minimal 15 kata, Mengandung minimal 5 huruf kapital, Diakhiri oleh titik (akhir kalimat).
Input    : data/training/prep/allSentences.txt
Output   : data/training/prep/all_good_sentences1.txt -> list of sentences yang sesuai kriteria.

7. Use Data5_IndoDetector.java to filter non Indonesian language
Requirement : https://github.com/shuyo/language-detection (Language Detection Tool), https://osdn.net/projects/jsonic/devel/ (bundle jsonic)
Fungsi : Memilih kalimat yang menggunakan Bahasa Indonesia saja.
input  : data/training/prep/all_good_sentences1.txt 
output : data/training/prep/all_ID_sentences.txt -> list of sentences yang berisi kalimat berbahasa Indonesia.

8. Use Data6_FileSplitter.py to split file from step 7, so that each file contains certain number of sentences
Fungsi : Membagi keseluruhan list of sentences kedalam file berbeda dengan -n jumlah kalimat per file.
Input  : data/training/prep/all_ID_sentences.txt
Output : data/training/prep/ID_sentences1_xx , dimana xx mulai dari 00 - n, sesuai jumlah kalimat.

9. Use Stanford NER library to format each file in step 8
Source : http://nlp.stanford.edu/software/CRF-NER.shtml#Download
code   : java -cp stanford-ner.jar edu.stanford.nlp.process.PTBTokenizer [file_input] > [file_output]
Fungsi : Membuat setiap baris hanya terdapat 1 kata (token)
Input  : data/training/prep/ID_sentences1_xx
Output : data/training/prep/ID_formatted1_xx, dimana xx mulai dari 00 - n, menyesuaikan ID_sentences1_xx.
 
10. Use NERIka_Tagger to automatically tag the data set
input 	: data/training/prep/ID_formatted1_xx
Output  : data/training/ready/ID_tagged1_xx, dimana xx mulai dari 00 - n, menyesuaikan ID_formatted1_xx.


Update untuk python 3 yang ditemukan di program:
	- not equal bukan lagi <> melainkan !=
	- untuk print, harus pakai kurung print (var)
	- perubahan untuk i/o (dikarenakan pesan error sering muncul dengan alasan unicode, maka untuk i/o pesan error dapat direplace dengan cara menambah  errors='replace' pada proses open file) Contoh : inputFile = open(input, "r", errors='replace')
	- tidak perlu menambahkan .encode dan .decode

	-----------------------------------------------------------------------------------------------------------------

Update 13 Februari 2017
	1. Task : Familiar dengan Stamford NER, jalanin demonya. Ubah kalimat jadi bentuk yang sesuai. Lihat file yang disebut di faq. Bisa ubah kalimat jadi token token.
	Already done :
	 - Download Download Stanford Named Entity Recognizer version 3.7.0  (http://nlp.stanford.edu/software/CRF-NER.shtml#Download)
	 - Mempelajari demo dari Stanford NER
	 	code : ner [nama_file]
	 		   versi panjangnya : java -mx600m -cp "*;lib\*" edu.stanford.nlp.ie.crf.CRFClassifier -loadClassifier classifiers/english.all.3class.distsim.crf.ser.gz -textFile [nama_file]
	  	Fungsi : untuk mengklasifikasi setiap kata di paragraf, apakah mengandung NER atau tidak (dalam bahasa Inggris)
	  	*jika ingin menyimpan hasil NER, gunakan command : ner [nama_file_input] > [nama_file_output]


	 	code : java -cp stanford-ner.jar edu.stanford.nlp.process.PTBTokenizer [file_input] > [file_output]
	 	Fungsi : Memotong tiap satu baris hanya terdiri satu kata (token).

	 Setelah data dipotong oleh Stanford NER (langkah 9), maka jadikan file yang sudah dalam bentuk token sebagai input untuk program NERIka_Tagger.py (langkah 10) lalu akan keluar file output yang sudah diberi label.

	 Langkah dari README.txt (progress) :
		9. Use Stanford NER library to format each file in step 8
		Source : http://nlp.stanford.edu/software/CRF-NER.shtml#Download
		code   : java -cp stanford-ner.jar edu.stanford.nlp.process.PTBTokenizer [file_input] > [file_output]
		Fungsi : Membuat setiap baris hanya terdapat 1 kata (token)
		Input  : data/training/prep/ID_sentences1_xx
		Output : data/training/prep/ID_formatted1_xx, dimana xx mulai dari 00 - n, menyesuaikan ID_sentences1_xx.
		 
		10. Use NERIka_Tagger to automatically tag the data set
		input 	: data/training/prep/ID_formatted1_xx
		Output  : data/training/ready/ID_tagged1_xx, dimana xx mulai dari 00 - n, menyesuaikan ID_formatted1_xx.


	2. DBPedia : potong potong
	Informasi tambahan : Type di DBPedia itu Organisation, bukan organization.
	---->Program sudah jadi. Input : text rdf dari DBPedia
							 Output: 3 file (person.txt , organization.txt, place.txt)


--------------------------------------------------------------------------------------------------------------

Progress Tanggal 23 Februari 
Task :
1. Ulang eksperimen seperti pada paper
How : 
	- buat file properties seperti contoh : http://nlp.stanford.edu/software/crf-faq.html
	- compile file properti (input : ID_tagged1_xx | output : outputmodelxx-xx.gz)
	  java -mx4g -cp stanford-ner.jar edu.stanford.nlp.ie.crf.CRFClassifier -prop [nama_file_prop]
	- test dengan data goldstandard
      java -cp stanford-ner.jar edu.stanford.nlp.ie.crf.CRFClassifier -loadClassifier outputmodelxx-xx.gz -testFile goldstandard-0811.txt

Progress :
Melakukan 13 kali percobaan dengan dataset berbeda. Hasil terbaik yang didapatkan : 
P-total = 0.8254 (outputmodel3-01.gz)
R-total = 0.2645 (outputmodel4.gz) 

2. Buat program untuk expanded.
Progress : 
Menghilangkan unicode pada data ('\xxxx') menjadi simbol tertentu.
code: 	import codecs
		 x = codecs.decode(dataValue[:-1], 'unicode_escape')

Mengganti tanda "_" dengan " "

Masalah encoding : set PYTHONIOENCODING=437:replace

----------------------------------------------------
Progress 1 Maret 2017
1. Mengulang program dengan 1000 kata, dikarenakan saat mencoba run dengan data yang jumlahnya 20000 selalu mengeluarkan java heap out of memory.

2. 
Melakukan cleansing ke data DBPedia
Person  : 	kata mengandung (grup xxx)  dan (band) pada Person dipindahkan ke Organization
			Terdapat 610 kata mengandung tanda kurung
Organization: Kata yang berasal dari person yang mengandung (grup...) akan masuk ke organization
Location	: none

Melakukan normalisasi ke data DBPedia
Person : - memisahkan nama AA bin/binti BB menjadi AA dan BB
		 - menghapus keterangan AA dari BB, contoh : Edward V dari Inggris menjadi Edward V
		   Ide : keterangan dibelakang kata dari bisa dipindahkan ke data Place. Namun, ternyata ada beberapa nama tempat yang sudah disediakan di data Place. 
		 - menghapus keterangan da, do, dos, de (Penamaan Portugis)
		 Dengan pertimbangan kata dibelakang da, do, dos, dan de tersebut adalah surname dari seseorang, maka kata tersebut juga bisa di tag menjadi Person. Maka jika menemukan : Juan Silveira dos Santos
		 Akan mejadi Juan Silveira, Santos
		 source : https://en.wikipedia.org/wiki/Portuguese_name
		 - Menghapus keterangan Jr. dan Sr. Jika ditemukan Martin Luther King, Jr. akan diubah menjadi Martin Luther King Jr. dan Martin Luther King. Penghapusan koma didasarkan karena aturan tersebut sudah tidak digunakan lagi untuk penamaan di Amerika maupun Inggris.
		 source : http://www.chicagomanualofstyle.org/qanda/data/faq/topics/Jr.Sr.III.html
Organization : menghilangkan keterangan (xx)
Location : menghilangkan keterangan (xx) dan memasukkan data yang didapat dari Person


Concern : pada data nama, ternyata masih terdapat data  : Karier Barack Obama di Senat Illinois, Pemilihan Bupati dan Wakil Bupati Kabupaten Bandung Barat 2013. Solusi : mungkin hapus manual. Pada RDF DBPedia di tag sebagai berikut :
<http://id.dbpedia.org/resource/Karier_Barack_Obama_di_Senat_Illinois><http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://dbpedia.org/ontology/Person> .


normalized dan expended
ulang 20000SENTENCES
CATAT IDE: huruf latin jadi biasa.

--------
expansion dan kumpulin yang aneh, nama orang yang pake angka (taro di cleansing si I-k)

------------------------------------------------------------------
Progress 8 Maret 2017
1. Melakukan expansion : menggunakan struktur data dictionary dengan {key : value} yang sama, jadi saat ingin memasukkan AA kedalam dictionary, akan menjadi {"AA" : "AA"}
	-Person : Pembuatan ekspansi unigram, bigram dan trigram. Untuk nama : AA BB CC akan dipecah menjadi 6 entry, yaitu : "AA BB CC", "AA", "BB","CC", "AA BB","BB CC".
	-Organization : Organisasi yang AA, BB dipecah jadi "AA, BB", "AA"
		contoh unik : "Konfederasi Sepak Bola Amerika Utara, Tengah, dan Karibia" sepertinya tidak akan dipecah karena merupakan suatu kesatuan.
	-Location : lokasi yang terpisah AA, BB dipecah tiga menjadi "AA, BB", "AA" dan "BB" 
Penggunaan Dictionary membuat output tidak memiliki urutan. Sehingga, setiap running urutan kata yang keluar akan selalu berubah-ubah.


perbaiki rule ekspansi place.
perbaiki generalisasi n-gram
cek kbbi apakah ada yang ngga valid
mempelajari program tagging
apa yang masih salah
nltk kadang nyimpen nama orang
eksplorasi isi nltk corpus english words

-----------------------------------------------------------------
Progress 15 Maret 2017
1. Generalisasi n-gram pada Person
	Untuk nama orang yang lebih dari 1 kata, potongan kata sampai n-gram sudah dapat di retrieve. Misal "AA BB CC" "AA BB CC", "AA", "BB","CC", "AA BB","BB CC" dengan jumlah n berapapun.
2. Perbaiki Rule di Place
	Rule "Aa, Bb, Cc" diubah menjadi "Aa", "Bb", dan "Cc" dengan pertimbangan di proses tagging nantinya akan terpisah oleh tanda koma.
3. Eksplorasi isi nltk  & Kebi
	Menemukan bahwa corpus nltk disimpan di sebuah folder nltk_data/corpora/words/en
	Membandingkan isinya dengan data valid
	Hal menarik : Seperti yang dikatakan Bu Ika, NLTK maupun KBBI menyimpan nama nama orang. 
	Yang dilakukan : menghapus manual dari Kebi maupun NLTK. 
	Concern : kadang nama belakang orang Inggris adalah kata biasa juga contoh : Park, Rose, Bloom, Weather, dll.
4. Penggunaan Dictionary: Struktur data yang memang tidak terurut. untuk mengurutkan, dapat menggunakan sorted(d.keys()) , namun berdasar leksikografi, bukan berdasar urutan memasukkan elemen. Maka, untuk data dari cleansing sampai expanded, saya menggunakan list[] sedangkan untuk data yang sudah validated, baru dimasukkan ke dictionary untuk mempercepan pemrosesan.
5. Membandingkan hasil tagging versi Bu Ika dengan versi baru , namun hasil masih sama. 

googling tentag WSD (word sense disambiguation)

---------------------------------------------
Progress 22 Maret 2017

1. Mempelajari WSD.
Membaca beberapa literatur dan slide mengenai WSD. Namun, kebanyakan penerapan WSD digunakan untuk disambiguisasi POS Tagging (berfokus pada noun, ataupun POS secara keseluruhan) untuk mencari makna apa yang tepat untuk suatu kata yang bersifat polysemi. Contoh bass (english), memiliki makna suara dan ikan. Setelah mencari, ada subfokus yang mempelajari mengenai ambiguitas pada NER, yaitu Named Entity Disambiguation
2. Mempelajari NED.
Mempelajari mengenai NED dari beberapa sumber. Ada paper yang melakukan POS Tagging terlebih dahulu untuk menentukkan named entity. Named entity dalam pos tagging akan selalu menjadi Proper Noun/Noun. 


identifikasi masalah kenapa recall, tampilkan semua ambigu dari kelas apa aja
----------------------------------------------------------------------------------
Progress 29 Maret
Identifikasi masalah :
1. Kode untuk melihat data ambigu.
Terdapat 279 kata ambigu
2. Kode untuk mengecek similarity 2 file.
Beberapa perbedaan dari hasil tagging bu ika dan saya.
3. Melihat pola kata kata yang ambigu (Untuk data ambigu Person dan Place, sudah terpikirkan untuk Place diawali kata "di", "ke", "dari". Namun, kalau Place diawal kalimat, bentuknya mirip dengan Person)
4. Menentukkan suatu kata NER atau bukan. 
Contoh : Britania Raya, atau Inggris Raya, adalah sebuah negara berdaulat yang terletak di lepas pantai barat laut benua Eropa. 
Ibu, apakah Eropa dikalimat tersebut bisa termasuk NER?



------------------------------------------------------------------------------
Progress 5 April 2017
1. Buang manual kata di person.txt
kata : Pemilihan Bupati dan Wakil Bupati Kabupaten Bandung Barat 2013
Karier Barack Obama di Senat Illinois

2. benarkan place (s)
membuang kata yang ada di kebi dan corpus nltk

3. Membuat rule
- Menambahkan nama kota dan negara ke dalam corpus , sumber : http://ilmupengetahuanumum.com/daftar-nama-negara-negara-di-dunia-beserta-ibukota-negara/
- Mengurangi entri dari NLTK dan KEBI karena ternyata banyak nama orang yang terambil di KEBI (masih hanya menghapus yang diawali huruf besar saja, dan beberapa pengapusan manual)
KEBI -> sebelum : 30217  sesudah : 29926
NLTK -> sebelum : 235883  sesudah : 210686
-Rule untuk kata ambigu 
	-Implementasi di, ke dan dari untuk ambiguitas antara Person dan Place [Untuk Place dengan Organization, belum tentu bisa menggunakan rule ini].
Sampai saat ini, hasil tagging menaikkan recall, namun menurunkan presisi (data yang digunakan masih mengikuti kemampuan laptop , hanya 1000 sentence , 31414 token)


---------------------------------------------------------------------------

Progress 12 April 2017
1. Membandingkan hasil standford ner dengan hasil tagging
2. Ide untuk rule Place
	- untuk tempat yang berawalan Selat, Gunung, Sungai, Teluk, Laut, Pulau, Bukit (masih dipikirkan beberapa kata lain), jika dilanjutkan kata berhuruf kapital, maka akan di tag sebagai Place.
	- masih ada grup (organisasi) yang tertinggal karena tidak ada keterangannya, contoh : Cherrybelle
3. Ide untuk rule Organization
	- Memisahkan kata Partai dengan nama partainya, misal entri : Partai Golongan Karya akan di expand menjadi Partai Golongan Karya dan Golongan Karya.
	- list singkatan partai : https://id.wikipedia.org/wiki/Daftar_partai_politik_di_Indonesia#Pemilu_2014
	- data masih bercampur dengan keterangan place
		SDI Assaadah, Jl.Swakarsa, Jakarta Timur
		ide : ingin memotong berdasar (,) maka yang diambil hanya kata pertama. Namun, jika entri sebagai berikut : Partai untuk Kasih, Kebebasan dan Keberagaman akan diberikan perlakuan khusus
	- Untuk institusi pendidikan (SMP ,SMA, SMPN, SMAN) jika diikuti angka, maka merupakan organisasi (masih dipikirkan)
4. Melakukan eksperimen dengan data lebih besar.
Mencoba di beberapa komputer lain, namun running time nya cukup lama (lebih dari 3 jam) lalu hasilnya juga tidak keluar


--------------------------------------------------------------------
Progress 17 April 2017
Tahap ekspansi data Organization
cleansing :
	- buang keterangan dalam kurung (xx) diakhir nama.
	- memasukkan nama grup musik dari entity Person
normalizing :
	- buang keterangan kurung di tengah kalimat
expand :
	- organization with coma seperator "aa, bb" is seperated into "aa, bb" and "aa"  
	- Untuk nama yang mengandung kata "Partai xx", maka akan dipecah menjadi "Partai xx" dan "xx". 
	- Penambahan nama partai serta singkatannya. source : https://id.wikipedia.org/wiki/Daftar_partai_politik_di_Indonesia#Pemilu_2014
	- Penambahan instansi pemerintah beserta singkatannya, source: https://www.menpan.go.id/jdih/permen-kepmen/permenpan-rb/file/3568-permenpan-2012-no-081?start=100
validate :
	-gabungkan entity dari organisation (expand), listPartai dan listInstansi (menggunakan dictionary untuk menjamin keunikan data)
Rule tambahan pada tagging :
-jika muncul kata "SD", "SDN", "SMP", "SMPN", "SMA", "SMAN", maka akan di tag sebagai Organisation



-----------------------------------------------------------------
Progress 19 April 2017
1. Membenarkan aturan di Organisation (filter kata di kebi maupun nltk)
2. Perbaikan rule untuk lembaga pendidikan (SD, SMP, DLL) hanya akan di tag jika dilanjutkan angka atau Huruf besar.
3. Perbaikan rule ambigu yang lebih spesifik
	- Untuk Person-Place-ORG akan di tag sebagai Place [melihat anggotanya hanya ada "Aceh" dan "Asia"]
	- Untuk Place-ORG, jika entrinya "Indonesia" akan di tag sebagai "Place"
4. Buat kode untuk keluaran standford NER (memisahkan TP, FN dan FP)
5. Melakukan eksperimen 10000 data
	[hasil dilampirkan pada dokumen drive yang sudah saya share dengan Ibu Ika.], f1 scorenya naik dari 43.58% menjadi 51.4%. 


---------------------------------------------------------------
Progress 25 April 2017
1. Melakukan eksperimen untuk 5000 dan 10000 kalimat.
2. Menambah rule untuk meningkatkan precission Person :
	- Buang nama yang mengandung bulan (April, Juni, Juli)
	- Tambahkan entry ejaan lama "oe" menjadi "u"
3. Buat kode untuk menghitung rule based murni. [CaculatePrecRec.py]
	Concern : sepertinya CRF melihat hasil dalam bentuk sequence, sedangkan kode yang saya buat untuk masing masing nilai. Maka, jika ada "Joko Widodo" yang aslinya adalah Person Person, dengan hasil prediksi Person Person, di kode yang saya buat akan dihitung sebagai 2 True Positive, sedangkan di CRF di tag sebagai 1 True Positive
Buat list hasil eksperimenn
5000
10000
20000
person usahain ngga dibawah 70% precissionnya
cari tau kenapa recall person naik hingga 13%
kirim ke Bu Ika untuk data 200000

rule based murni -> goldstandard tanpa label, bandingkan dengan CRF.

Ide rule : nama dengan ejaann lama juga dibuat versi ejaan barunya. Misal : Soekarno menjadi Sukarno
April, Juni jadi Person
Juli jadi Place
1. Di beberapa negara Barat[Place],nama Soekarno kadang-kadang ditulis Achmed Soekarno.
Apakah Barat di tag sebagai Place, Bu?
2. Dalam beberapa versi lain, disebutkan pemberian nama Achmed[Person] di depan nama Sukarno[Person], dilakukan oleh para diplomat muslim asal Indonesia[Place] yang sedang melakukan misi luar[Place] negeri[Place] dalam upaya untuk mendapatkan pengakuan kedaulatan negara Indonesia[Place] oleh negara[Place] - negara[Place] Arab[Place].
3. Melalui ajang pencarian bakat Cherrybelle[ORGANISATION] Cari Chibi[ORGANISATION], pada tangga l8 Juni 2012, Kezia dan Steffy terpilih menjadi anggota barunya.
Sepertinya Chibi disini bukan organisation, bu. Karena Chibi adalah panggilan untuk 1 orang personel saja.


How to make the expansion?
1. Cleansing
- PersonCleansing.py [menghasilkan file person.txt dan place.txt di folder cleansing]
- OrganizationCleansing.py
2. Normalization
- PersonNormalization.py
- PlaceNormalization.py
- OrganizationNormalization.py
3. Expansion
- PersonExpansion.py
- PlaceExpansion.py
- OrganizationExpansion.py
- OrganizationMergedPartai.py [melakukan ekspansi dari file original/listPartai.txt , dan menyimpan hasilnya pada folder expanded/listPartai.txt]
4. Validate [semua file dalam bentuk dictionary untuk menjamin keunikan entry]
- PersonValidate.py
- PlaceValidate.py
- OrganizationValidate.py [menggabungkan hasil expanded organisasi, expanded listPartai dan original listInstansi]


1. Coba rule Cleansing Person : nama di stem, jika semua kata ada dikamus, buang entry nya.
2. Buat perbedaan entry DBPedia (yang sama, yang ada di buika tapi gaaada diaku dan sebaliknya)
3. perubahan : NLTK Inggrisnya dibuang huruf besar.


-----------------------------------------------------------------
28 April 2017

1. Membuang entry Person yang memiliki stem yang seluruhnya ada di NLTK
	(karena beberapa nama band tidak semua potongan katanya ada di NLTK, dibuat aturan tambahan, jika nama tersebut mengandung the, maka akan dibuang).
	Hasil : 93 entry terfilter.
2. Membuat kode untuk binding data DBPedia X dan DBPedia Y.


Person
Buat rule untuk KH. Dr. 
Urus & pada person
Ekspansi untuk nama mengandung bin. xx bin yy, xx , yy
Untuk bin, persiapan ekspansi adalah, saat normalisasi cuma ada xx dan yy, lalu yang ke ekspan hanya xx dan yy saja.
Buat DBPedia BuIka versi 2, (masukkan kembali band-band berbahasa inggris).
Proposed method setiap kategori , perubahan rule apa saja
perubahan rule tagging (ambiguitas)
cari tahu apakah yang dikerjakan ini termasuk WSD.
Aturan seluruh kata ada dikamus, cek untuk bahasa Indonesia.

Membagi poin (k) jadi beberapa:
1. Memperkenalkan kategori nama baru : Nama yang seluruh katanya ada di kamus.
2. Mengandung The(nama yang diawali oleh artikel).
3. Nama mengandung angka

Mengubah poin(f) dos
Menambah kategori Nama Person untuk Awalan gelar (KH, DR, DRS)


Buat kolom original dan expanded data DBPedia dengan rule yang di revisi

Ceritakan tagging proses ada ambiguitas

Belaja

-----------------------------------------------
progress 2 Mei 2017
1. Memperbaiki aturan Person Cleansing
	-Ternyata kode sebelumnya bukan mengetag seluruh kata yang ada di kamus, namun hanya melihat kata apa yang mengandung "the". Maka, setelah rule diperbaiki, banyak sekali nama orang yang ikut terfilter. Akhirnya, saya tidak menggunakan corpus NLTK karena kata-kata yang ada disana terlalu universal dan masih banyak nama orang yang terdaftar. Kamus bahasa Inggris diganti dengan : http://www.wordfrequency.info/top5000.asp yang hanya terdiri 5000 kata. Hasilnya, dapat memfilter 203 kata. Nama orang yang terbawa masuk :  Bill Gates, Bill Steer, Jared Diamond
	-Membuat rule untuk &. Karena sepertinya cukup berbahaya, akhirnya semua entry yang mengandung & dibuang.
2. Membuat DBPedia Ibu Ika v1 (dengan tambahan data Person yang tidak valid), 
3. Membuat draft proposed method untuk paper dalam 2 versi [Indonesia dan Inggris]


1. evaluasi orgininal vitri dan buika. analisa bedanya kenapa.

kesalahan goldstandard
1279-1282
1394 CEO
4577 Doraemon
11000 Gary


a) kenapa akurasi Person berkurang?
1. Terdapat nama Milan di Person, namun tidak ada di Organization maupun Place
Solusi: memasukkan nama kota Milan pada Place dengan sumber data : https://id.wikipedia.org/wiki/Daftar_kota_menurut_PDB
2. Masih mengandung kata dengan huruf besar semua
3. Kata yang terfilter hanya dari nltk_clean (sudah terlampir percobaan)

b) Malah KEBI, karena semua huruf kapital dibuang, nama agama juga turut terbuang. Dikarenakan pada Organization terdapat "Partai Katolik", yang diexpand menjadi "Katolik", kata tersebut tidak terfilter.
Solusi : Pada data kebi yang sudah dihilangkan huruf besar, diberikan rule tambahan untuk menambahkan agama yang didapat dari source : https://id.wikipedia.org/wiki/Agama_di_Indonesia

1. validate tambah rule Agama
2. cari di Kebi yang huruf besar sebenarnya cenderung nama semua atau gimana
3. perbedaan sumber DBPedia original , tahap cleansing , normalisasi , ekspan, validate

Tugas besok :
1. Benerin ekspansi Place (harusnya n-gram)
	masi ada data "  ", cek lagi

benerin :
Normalisasi Place :
1. concat dengan "Departemen"

Progress 24 Mei :
Progress bab 2, 3 dan 4


skenario bebas.
1 cerita  1 skenario
nltk nya coba pake yang full


Gimana cara evaluasii???
1. ChangeOutputToIOB.py -> ngubah output IO menjadi IOB 
input : fileIO.txt
output : fileIOB.txt

2. EvaluationIOB.py -> evaluasi IOB buat itu prec recall and f1